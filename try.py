# -*- coding: utf-8 -*-
"""try.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wn1oEZDiZKPbJCHgEokgBlVOo-hzdIHH
"""

import torch
import torch.nn as nn
import torch.optim as optim

# Data
pairs = [
    ("I eat rice", "म भात खान्छु"),
    ("I eat apple", "म स्याउ खान्छु"),
    ("He drinks water", "ऊ पानी पिउँछ"),
    ("She goes home", "ऊ घर जान्छ"),
]

# Build vocab
def build_vocab(sentences):
    vocab = {"<s>":0}
    for s in sentences:
        for w in s.split():
            if w not in vocab:
                vocab[w] = len(vocab)
    return vocab

eng_vocab = build_vocab([p[0] for p in pairs])
nep_vocab = build_vocab([p[1] for p in pairs])
inv_nep = {v:k for k,v in nep_vocab.items()}

def encode(sentence, vocab):
    return torch.tensor([[vocab[w] for w in sentence.split()]])

# Model
class Encoder(nn.Module):
    def __init__(self, v):
        super().__init__()
        self.emb = nn.Embedding(v, 16)
        self.rnn = nn.RNN(16, 32, batch_first=True)
    def forward(self, x):
        _, h = self.rnn(self.emb(x))
        return h

class Decoder(nn.Module):
    def __init__(self, v):
        super().__init__()
        self.emb = nn.Embedding(v, 16)
        self.rnn = nn.RNN(16, 32, batch_first=True)
        self.fc = nn.Linear(32, v)
    def forward(self, x, h):
        out, _ = self.rnn(self.emb(x), h)
        return self.fc(out)

enc = Encoder(len(eng_vocab))
dec = Decoder(len(nep_vocab))

opt = optim.Adam(list(enc.parameters()) + list(dec.parameters()), lr=0.01)
loss_fn = nn.CrossEntropyLoss()

# Train
for _ in range(500):
    for e, n in pairs:
        src = encode(e, eng_vocab)
        tgt = encode("<s> " + n, nep_vocab)
        opt.zero_grad()
        h = enc(src)
        out = dec(tgt[:, :-1], h)
        loss = loss_fn(out.reshape(-1, out.size(-1)), tgt[:, 1:].reshape(-1))
        loss.backward()
        opt.step()

# Test
def translate(sentence):
    src = encode(sentence, eng_vocab)
    h = enc(src)
    x = torch.tensor([[nep_vocab["<s>"]]])
    words = []
    for _ in range(5):
        out = dec(x, h)
        w = out.argmax(-1)[:,-1].item()
        word = inv_nep[w]
        words.append(word)
        x = torch.cat([x, torch.tensor([[w]])], dim=1)
    return " ".join(words)

print(translate("I eat rice"))